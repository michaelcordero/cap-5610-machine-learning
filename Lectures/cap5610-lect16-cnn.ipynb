{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Convolutional neural network with Keras\n\nIn this demo, we will train and test a CNN model on the CIFAR10 dataset using Keras.","metadata":{"id":"63GSckRspoZJ"}},{"cell_type":"markdown","source":"## 1. Load dataset\n\nThe following code snippet will download the data, load it into memory, and convert pixel values to [0, 1].","metadata":{"id":"8aieNmVBO2II"}},{"cell_type":"code","source":"from keras.datasets import cifar10\n\n(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\nX_train = X_train.astype('float32') / 255\nX_test = X_test.astype('float32') / 255\n\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape, Y_test.shape)","metadata":{"id":"N8WM9P0lLYas","execution":{"iopub.status.busy":"2022-03-15T23:15:40.260615Z","iopub.execute_input":"2022-03-15T23:15:40.260934Z","iopub.status.idle":"2022-03-15T23:15:53.30986Z","shell.execute_reply.started":"2022-03-15T23:15:40.260867Z","shell.execute_reply":"2022-03-15T23:15:53.309116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Show a few training examples and its label","metadata":{"id":"3myKOyEtiAfy"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# List of label strings for CIFAR10\nlabel_str = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n\nimg_id = 15\nimage = X_train[img_id]\nlabel = Y_train[img_id]\n\nplt.imshow(image)\nplt.show()\nprint(label_str[label[0]])","metadata":{"id":"7NvcF5oziEos","execution":{"iopub.status.busy":"2022-03-15T23:16:47.559722Z","iopub.execute_input":"2022-03-15T23:16:47.559972Z","iopub.status.idle":"2022-03-15T23:16:47.72703Z","shell.execute_reply.started":"2022-03-15T23:16:47.559946Z","shell.execute_reply":"2022-03-15T23:16:47.726047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Convert label vectors into one-hot encodings","metadata":{"id":"8QWJNivcjh-u"}},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n\nnum_classes = 10\nY_train = to_categorical(Y_train, num_classes)\nY_test = to_categorical(Y_test, num_classes)\n\nprint(Y_train.shape, Y_test.shape)","metadata":{"id":"Q-BZ2Yy_jlTP","execution":{"iopub.status.busy":"2022-03-15T23:17:01.797023Z","iopub.execute_input":"2022-03-15T23:17:01.797275Z","iopub.status.idle":"2022-03-15T23:17:02.096968Z","shell.execute_reply.started":"2022-03-15T23:17:01.797248Z","shell.execute_reply":"2022-03-15T23:17:02.09567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Define the CNN model\n\nWe can add convolutional layers using the Conv2D class and max pooling layer using the MaxPooling2D class. The CNN below is a variant of LeNet-5, with the input being a color image of size 32 x 32 x 3.\n\n","metadata":{"id":"gm7gkMbpjuUh"}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, AveragePooling2D, Flatten, Dropout\n\nmodel = Sequential()\nmodel.add(Conv2D(6, (5, 5), activation='relu', padding='same', input_shape=(32, 32, 3)))\nmodel.add(AveragePooling2D((2, 2)))\nmodel.add(Conv2D(16, (5, 5), activation='relu', padding='same'))\nmodel.add(AveragePooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(120, activation='relu'))\nmodel.add(Dense(84, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-03-15T23:28:28.204274Z","iopub.execute_input":"2022-03-15T23:28:28.204558Z","iopub.status.idle":"2022-03-15T23:28:28.262478Z","shell.execute_reply.started":"2022-03-15T23:28:28.204531Z","shell.execute_reply":"2022-03-15T23:28:28.261676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Compile the model","metadata":{"id":"-DdumpAjlrC-"}},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])","metadata":{"id":"--ZnjFmXkKXO","execution":{"iopub.status.busy":"2022-03-15T23:28:31.84372Z","iopub.execute_input":"2022-03-15T23:28:31.84398Z","iopub.status.idle":"2022-03-15T23:28:31.85481Z","shell.execute_reply.started":"2022-03-15T23:28:31.843955Z","shell.execute_reply":"2022-03-15T23:28:31.854043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Train the model","metadata":{"id":"aNEsQIi-luh2"}},{"cell_type":"code","source":"model.fit(X_train, Y_train, epochs=100, batch_size=128)","metadata":{"id":"m4rqyov4kK_K","execution":{"iopub.status.busy":"2022-03-15T23:28:34.435926Z","iopub.execute_input":"2022-03-15T23:28:34.43618Z","iopub.status.idle":"2022-03-15T23:30:59.468138Z","shell.execute_reply.started":"2022-03-15T23:28:34.436152Z","shell.execute_reply":"2022-03-15T23:30:59.467482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Evaluate the trained model on test set","metadata":{"id":"UGshOAWKlxif"}},{"cell_type":"code","source":"accuracy = model.evaluate(X_test, Y_test)[1]\n\nprint(accuracy)","metadata":{"id":"8hT_J7OKkPde","execution":{"iopub.status.busy":"2022-03-15T23:31:18.966423Z","iopub.execute_input":"2022-03-15T23:31:18.966973Z","iopub.status.idle":"2022-03-15T23:31:20.15871Z","shell.execute_reply.started":"2022-03-15T23:31:18.966935Z","shell.execute_reply":"2022-03-15T23:31:20.158025Z"},"trusted":true},"execution_count":null,"outputs":[]}]}