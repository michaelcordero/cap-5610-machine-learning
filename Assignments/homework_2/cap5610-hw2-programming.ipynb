{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Load CIFAR-10 Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 01:42:23.652024: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "num_classes = 10\n",
    "Y_train = to_categorical(Y_train, num_classes)\n",
    "Y_test = to_categorical(Y_test, num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T01:42:23.590716Z",
     "end_time": "2023-04-04T01:42:27.355053Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train and evaluate the VGG Model with 3 blocks without BatchNorm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# VGG block\n",
    "for i in range(3):\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully-connected part\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=30, batch_size=128)\n",
    "accuracy = model.evaluate(X_test, Y_test)[1]\n",
    "\n",
    "print(f'Without BatchNorm: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modify the model in Question 3.1 to add BatchNorm after the Flatten layer and before the fully-connected part. Train and evaluate this model.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "98/98 [==============================] - 83s 842ms/step - loss: 2.0733 - accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "98/98 [==============================] - 81s 826ms/step - loss: 1.8095 - accuracy: 0.3566\n",
      "Epoch 3/30\n",
      "98/98 [==============================] - 81s 830ms/step - loss: 1.6508 - accuracy: 0.4094\n",
      "Epoch 4/30\n",
      "98/98 [==============================] - 80s 820ms/step - loss: 1.5608 - accuracy: 0.4423\n",
      "Epoch 5/30\n",
      "98/98 [==============================] - 80s 821ms/step - loss: 1.5027 - accuracy: 0.4622\n",
      "Epoch 6/30\n",
      "98/98 [==============================] - 82s 839ms/step - loss: 1.4457 - accuracy: 0.4810\n",
      "Epoch 7/30\n",
      "98/98 [==============================] - 81s 827ms/step - loss: 1.4041 - accuracy: 0.4979\n",
      "Epoch 8/30\n",
      "98/98 [==============================] - 81s 828ms/step - loss: 1.3635 - accuracy: 0.5123\n",
      "Epoch 9/30\n",
      "98/98 [==============================] - 81s 825ms/step - loss: 1.3301 - accuracy: 0.5242\n",
      "Epoch 10/30\n",
      "98/98 [==============================] - 82s 839ms/step - loss: 1.2995 - accuracy: 0.5369\n",
      "Epoch 11/30\n",
      "98/98 [==============================] - 81s 831ms/step - loss: 1.2686 - accuracy: 0.5482\n",
      "Epoch 12/30\n",
      "98/98 [==============================] - 81s 829ms/step - loss: 1.2413 - accuracy: 0.5595\n",
      "Epoch 13/30\n",
      "98/98 [==============================] - 81s 822ms/step - loss: 1.2166 - accuracy: 0.5681\n",
      "Epoch 14/30\n",
      "98/98 [==============================] - 81s 826ms/step - loss: 1.1915 - accuracy: 0.5783\n",
      "Epoch 15/30\n",
      "98/98 [==============================] - 81s 828ms/step - loss: 1.1691 - accuracy: 0.5868\n",
      "Epoch 16/30\n",
      "98/98 [==============================] - 81s 827ms/step - loss: 1.1473 - accuracy: 0.5951\n",
      "Epoch 17/30\n",
      "98/98 [==============================] - 82s 838ms/step - loss: 1.1245 - accuracy: 0.6040\n",
      "Epoch 18/30\n",
      "98/98 [==============================] - 82s 832ms/step - loss: 1.1063 - accuracy: 0.6109\n",
      "Epoch 19/30\n",
      "98/98 [==============================] - 81s 823ms/step - loss: 1.0858 - accuracy: 0.6178\n",
      "Epoch 20/30\n",
      "98/98 [==============================] - 81s 829ms/step - loss: 1.0669 - accuracy: 0.6254\n",
      "Epoch 21/30\n",
      "98/98 [==============================] - 80s 813ms/step - loss: 1.0524 - accuracy: 0.6299\n",
      "Epoch 22/30\n",
      "98/98 [==============================] - 81s 823ms/step - loss: 1.0341 - accuracy: 0.6380\n",
      "Epoch 23/30\n",
      "98/98 [==============================] - 82s 837ms/step - loss: 1.0205 - accuracy: 0.6436\n",
      "Epoch 24/30\n",
      "98/98 [==============================] - 81s 828ms/step - loss: 1.0014 - accuracy: 0.6499\n",
      "Epoch 25/30\n",
      "98/98 [==============================] - 80s 818ms/step - loss: 0.9854 - accuracy: 0.6561\n",
      "Epoch 26/30\n",
      "98/98 [==============================] - 81s 821ms/step - loss: 0.9720 - accuracy: 0.6587\n",
      "Epoch 27/30\n",
      "98/98 [==============================] - 81s 827ms/step - loss: 0.9580 - accuracy: 0.6640\n",
      "Epoch 28/30\n",
      "98/98 [==============================] - 82s 838ms/step - loss: 0.9420 - accuracy: 0.6698\n",
      "Epoch 29/30\n",
      "98/98 [==============================] - 82s 840ms/step - loss: 0.9303 - accuracy: 0.6722\n",
      "Epoch 30/30\n",
      "98/98 [==============================] - 81s 823ms/step - loss: 0.9152 - accuracy: 0.6781\n",
      "313/313 [==============================] - 32s 103ms/step - loss: 1.0773 - accuracy: 0.6262\n",
      "0.6262000203132629\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "batch_model = Sequential()\n",
    "\n",
    "# VGG block\n",
    "for i in range(3):\n",
    "    batch_model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "    batch_model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    batch_model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten\n",
    "batch_model.add(Flatten())\n",
    "batch_model.add(BatchNormalization())\n",
    "\n",
    "# Fully-connected part\n",
    "batch_model.add(Dense(128, activation='relu'))\n",
    "batch_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "batch_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "batch_model.fit(X_train, Y_train, epochs=30, batch_size=128)\n",
    "accuracy = batch_model.evaluate(X_test, Y_test)[1]\n",
    "\n",
    "print(f'With BatchNorm: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T00:15:40.298450Z",
     "end_time": "2023-04-04T00:56:49.515500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modify the model in Question 3.2 to add Dropout layer with rate 0.1 right before the Softmax layer. Train and evaluate this model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 01:42:27.364956: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-04 01:42:27.378083: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "196/196 [==============================] - 162s 821ms/step - loss: 1.9681 - accuracy: 0.2925\n",
      "Epoch 2/30\n",
      "196/196 [==============================] - 164s 834ms/step - loss: 1.6434 - accuracy: 0.4075\n",
      "Epoch 3/30\n",
      "196/196 [==============================] - 160s 815ms/step - loss: 1.4995 - accuracy: 0.4572\n",
      "Epoch 4/30\n",
      "196/196 [==============================] - 159s 814ms/step - loss: 1.4160 - accuracy: 0.4918\n",
      "Epoch 5/30\n",
      "196/196 [==============================] - 159s 809ms/step - loss: 1.3490 - accuracy: 0.5170\n",
      "Epoch 6/30\n",
      "196/196 [==============================] - 161s 819ms/step - loss: 1.2986 - accuracy: 0.5378\n",
      "Epoch 7/30\n",
      "196/196 [==============================] - 159s 811ms/step - loss: 1.2533 - accuracy: 0.5519\n",
      "Epoch 8/30\n",
      "196/196 [==============================] - 157s 799ms/step - loss: 1.2094 - accuracy: 0.5693\n",
      "Epoch 9/30\n",
      "196/196 [==============================] - 161s 823ms/step - loss: 1.1745 - accuracy: 0.5835\n",
      "Epoch 10/30\n",
      "196/196 [==============================] - 159s 813ms/step - loss: 1.1392 - accuracy: 0.5952\n",
      "Epoch 11/30\n",
      "196/196 [==============================] - 156s 798ms/step - loss: 1.1026 - accuracy: 0.6108\n",
      "Epoch 12/30\n",
      "196/196 [==============================] - 158s 807ms/step - loss: 1.0714 - accuracy: 0.6209\n",
      "Epoch 13/30\n",
      "196/196 [==============================] - 157s 802ms/step - loss: 1.0396 - accuracy: 0.6327\n",
      "Epoch 14/30\n",
      "196/196 [==============================] - 156s 796ms/step - loss: 1.0113 - accuracy: 0.6437\n",
      "Epoch 15/30\n",
      "196/196 [==============================] - 158s 806ms/step - loss: 0.9869 - accuracy: 0.6529\n",
      "Epoch 16/30\n",
      "196/196 [==============================] - 156s 793ms/step - loss: 0.9597 - accuracy: 0.6632\n",
      "Epoch 17/30\n",
      "196/196 [==============================] - 158s 808ms/step - loss: 0.9342 - accuracy: 0.6713\n",
      "Epoch 18/30\n",
      "196/196 [==============================] - 158s 804ms/step - loss: 0.9162 - accuracy: 0.6764\n",
      "Epoch 19/30\n",
      "196/196 [==============================] - 160s 814ms/step - loss: 0.8948 - accuracy: 0.6857\n",
      "Epoch 20/30\n",
      "196/196 [==============================] - 158s 807ms/step - loss: 0.8781 - accuracy: 0.6908\n",
      "Epoch 21/30\n",
      "196/196 [==============================] - 160s 815ms/step - loss: 0.8614 - accuracy: 0.6981\n",
      "Epoch 22/30\n",
      "196/196 [==============================] - 157s 803ms/step - loss: 0.8480 - accuracy: 0.7031\n",
      "Epoch 23/30\n",
      "196/196 [==============================] - 158s 808ms/step - loss: 0.8325 - accuracy: 0.7083\n",
      "Epoch 24/30\n",
      "196/196 [==============================] - 159s 809ms/step - loss: 0.8210 - accuracy: 0.7096\n",
      "Epoch 25/30\n",
      "196/196 [==============================] - 161s 821ms/step - loss: 0.8040 - accuracy: 0.7178\n",
      "Epoch 26/30\n",
      "196/196 [==============================] - 158s 806ms/step - loss: 0.7925 - accuracy: 0.7213\n",
      "Epoch 27/30\n",
      "196/196 [==============================] - 158s 808ms/step - loss: 0.7818 - accuracy: 0.7261\n",
      "Epoch 28/30\n",
      "196/196 [==============================] - 155s 791ms/step - loss: 0.7724 - accuracy: 0.7290\n",
      "Epoch 29/30\n",
      "196/196 [==============================] - 160s 817ms/step - loss: 0.7611 - accuracy: 0.7339\n",
      "Epoch 30/30\n",
      "196/196 [==============================] - 159s 812ms/step - loss: 0.7500 - accuracy: 0.7385\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 1.2984 - accuracy: 0.5556\n",
      "0.5555999875068665\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "batch_model = Sequential()\n",
    "\n",
    "# VGG block\n",
    "for i in range(3):\n",
    "    batch_model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "    batch_model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    batch_model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten\n",
    "batch_model.add(Flatten())\n",
    "batch_model.add(BatchNormalization())\n",
    "\n",
    "# Fully-connected part\n",
    "batch_model.add(Dense(128, activation='relu'))\n",
    "batch_model.add(Dropout(0.1))\n",
    "batch_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "batch_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "batch_model.fit(X_train, Y_train, epochs=30, batch_size=128)\n",
    "accuracy = batch_model.evaluate(X_test, Y_test)[1]\n",
    "\n",
    "print(f'With Dropout Layer: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-04T01:42:27.354144Z",
     "end_time": "2023-04-04T03:02:22.003744Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
